<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Inner Voice - An interactive audio visualization experiment using SVG animations">
    <title>Audio Reactive Visualization</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #1A2A50;
            margin: 0;
            color: white;
            font-family: sans-serif;
        }
        
        .controls {
            margin-bottom: 20px;
            display: flex;
            gap: 10px;
            align-items: center;
        }
        
        .device-selector {
            padding: 5px;
            margin-left: 10px;
            min-width: 250px;
            background: #333;
            color: white;
            border: 1px solid #555;
            border-radius: 4px;
        }
        
        button {
            padding: 6px 12px;
            background: #0066FF;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        
        button:disabled {
            background: #555;
            cursor: not-allowed;
        }
        
        .svg-container-wrapper {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 0;
        }
        
        .svg-container {
            width: 300px;
            height: 280px;
            position: relative;
            overflow: visible; /* Allow SVG to overflow its container */
        }

        svg {
            width: 100%;
            height: 100%;
            overflow: visible; /* Allow paths to overflow SVG boundary */
            color:white;
        }
        
        .r-path {
            transform-origin: center;
            transition: d 0.08s ease-out;
            color:white;
        }
        
        #debug-info {
            position: fixed;
            bottom: 10px;
            left: 10px;
            font-size: 12px;
            opacity: 0.7;
            color: white;
        }
    </style>
</head>
<body>
    <div class="controls">
        <button id="start-audio">Start Microphone</button>
        <button id="stop-audio" disabled>Stop Microphone</button>
        <select id="audio-devices" class="device-selector">
            <option value="">Loading devices...</option>
        </select>
        <button id="refresh-devices">‚ü≥</button>
    </div>
    <div class="svg-container-wrapper">
        <div class="svg-container">
            <!-- Center the SVG in its container for better positioning -->
            <svg width="300" height="280" viewBox="0 0 200 60" preserveAspectRatio="xMidYMid meet" fill="none" xmlns="http://www.w3.org/2000/svg">
                <!-- Center the group of paths and space them evenly with no gaps -->
                <path class="r-path" transform="translate(85, 0)" d="M15 30C1.6278 35.8581 13.8786 46.6175 8 60C2.12138 46.6175 13.3619 35.8581 0 30C13.3722 24.1419 2.12138 13.3825 8 0C13.8786 13.3825 1.63809 24.1419 15 30Z" fill="white"/>
                <path class="r-path" transform="translate(100, 0)" d="M15 30C1.6278 35.8581 13.8786 46.6175 8 60C2.12138 46.6175 13.3619 35.8581 0 30C13.3722 24.1419 2.12138 13.3825 8 0C13.8786 13.3825 1.63809 24.1419 15 30Z" fill="white"/>
                <path class="r-path" transform="translate(115, 0)" d="M15 30C1.6278 35.8581 13.8786 46.6175 8 60C2.12138 46.6175 13.3619 35.8581 0 30C13.3722 24.1419 2.12138 13.3825 8 0C13.8786 13.3825 1.63809 24.1419 15 30Z" fill="white"/>
                <path class="r-path" transform="translate(130, 0)" d="M15 30C1.6278 35.8581 13.8786 46.6175 8 60C2.12138 46.6175 13.3619 35.8581 0 30C13.3722 24.1419 2.12138 13.3825 8 0C13.8786 13.3825 1.63809 24.1419 15 30Z" fill="white"/>
                <path class="r-path" transform="translate(145, 0)" d="M15 30C1.6278 35.8581 13.8786 46.6175 8 60C2.12138 46.6175 13.3619 35.8581 0 30C13.3722 24.1419 2.12138 13.3825 8 0C13.8786 13.3825 1.63809 24.1419 15 30Z" fill="white"/>
            </svg>
        </div>
    </div>
    
    <div id="debug-info"></div>

    <script>
        // Debug element
        const debugInfo = document.getElementById('debug-info');
        
        // Audio context and analyzer
        let audioContext;
        let analyzer;
        let microphone;
        let stream;
        let isAudioRunning = false;
        const paths = document.querySelectorAll('.r-path');
        const audioDeviceSelect = document.getElementById('audio-devices');
        const refreshDevicesBtn = document.getElementById('refresh-devices');

        // Animation keyframes for the R shape
        const keyframes = [
            { // Default state - exact size of R.svg
                rightX: 15,   // Original R.svg width
                leftX: 0,     // Original left edge
                topY: 0,      // Original top edge
                bottomY: 60,  // Original bottom edge
                centerY: 30,
                centerX: 8
            },
            { // Contracted state (more aggressive)
                rightX: 11,
                leftX: 5,
                topY: 20,
                bottomY: 40,
                centerY: 30,
                centerX: 8
            },
            { // Expanded state
                rightX: 27,   // Larger when expanded
                leftX: -12,
                topY: -17,
                bottomY: 77,
                centerY: 30,
                centerX: 8
            }
        ];
        
        // Animation timing
        const frameTiming = [0, 100, 200, 300, 400];
        
        // Total animation duration in seconds
        const totalDuration = 4;
        
        // Base path template with control points from animation.json
        const basePathData = {
            rightX: 63.87523,
            leftX: 0,
            topY: 0,
            bottomY: 63.87523,
            centerY: 31.93762,
            centerX: 31.93762,
            // Control points from animation.json
            controlPoints: {
                topRight: { x: 14.23587, y: 6.23641 },
                topLeft: { x: 6.25831, y: 14.24682 },
                bottomRight: { x: 14.22492, y: 6.23641 },
                bottomLeft: { x: 6.25831, y: 14.24682 },
                rightTop: { x: 14.22492, y: 6.23641 },
                rightBottom: { x: 14.23587, y: 6.23641 },
                leftTop: { x: 6.25831, y: 14.24682 },
                leftBottom: { x: 6.25831, y: 14.24682 }
            }
        };
        
        // Default animation cycle when no audio is detected
        let animationFrame;
        let defaultAnimationTime = 0;
        
        // Load available audio input devices 
        async function loadAudioDevices() {
            try {
                audioDeviceSelect.innerHTML = '<option value="">Loading devices...</option>';
                
                // Safely list all available devices without requiring permission first
                let devices = await navigator.mediaDevices.enumerateDevices();
                let audioInputs = devices.filter(device => device.kind === 'audioinput');
                
                // Clear the dropdown
                audioDeviceSelect.innerHTML = '';
                
                // Add default option
                const defaultOption = document.createElement('option');
                defaultOption.value = "";
                defaultOption.text = "Default Microphone";
                audioDeviceSelect.appendChild(defaultOption);
                
                // Add each audio input device to the dropdown
                audioInputs.forEach((device, index) => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.text = device.label || `Microphone ${index + 1}`;
                    audioDeviceSelect.appendChild(option);
                });
                
                // Check if permissions were previously granted
                const hasLabels = audioInputs.some(device => device.label && device.label.length > 0);
                
                if (!hasLabels) {
                    debugInfo.textContent = "Click 'Start Microphone' to enable full device names";
                } else {
                    debugInfo.textContent = `Found ${audioInputs.length} audio devices`;
                }
                
                if (audioInputs.length === 0) {
                    audioDeviceSelect.innerHTML = '<option value="">No microphones found</option>';
                    debugInfo.textContent = "No audio input devices detected";
                }
            } catch (error) {
                console.error("Error loading audio devices:", error);
                debugInfo.textContent = `Error: ${error.message}`;
                audioDeviceSelect.innerHTML = '<option value="">Unable to access devices</option>';
            }
        }
        
        // Start the default animation that runs when not using microphone
        function startDefaultAnimation() {
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
            }
            
            // Set all paths to their default state without animation
            paths.forEach((path) => {
                updatePath(path, keyframes[0]);
            });
        }
        
        // Cubic bezier easing function based on animation.json (0.75, 0.75, 0.25, 0.25)
        function cubicBezier(x1, y1, x2, y2, t) {
            // Approximation of cubic bezier calculation for easing
            return t * t * (3.0 - 2.0 * t);
        }
        
        // Linear interpolation helper
        function lerp(start, end, t) {
            return start * (1 - t) + end * t;
        }
        
        // Initialize audio context and analyzer
        async function setupAudio() {
            try {
                // Create audio context on demand
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                } else if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                debugInfo.textContent = "Requesting microphone access...";
                
                // Create analyzer node if needed
                if (!analyzer) {
                    analyzer = audioContext.createAnalyser();
                    analyzer.fftSize = 2048;
                    analyzer.smoothingTimeConstant = 0.85;
                }
                
                // Stop any existing stream before creating a new one
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                
                // Get selected device ID (or use default if none selected)
                const deviceId = audioDeviceSelect.value;
                
                // Configure constraints - simplify to improve compatibility
                const constraints = {
                    audio: true
                };
                
                // Only add deviceId if one is specifically selected
                if (deviceId) {
                    constraints.audio = {
                        deviceId: {exact: deviceId}
                    };
                }
                
                // Request microphone access
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Now that we have permission, get the complete device list with labels
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputs = devices.filter(device => device.kind === 'audioinput');
                
                // Update dropdown with full device information
                audioDeviceSelect.innerHTML = '';
                
                // Add default option
                const defaultOption = document.createElement('option');
                defaultOption.value = "";
                defaultOption.text = "Default Microphone";
                audioDeviceSelect.appendChild(defaultOption);
                
                // Populate all devices with their proper labels
                audioInputs.forEach((device, index) => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    // Now we should have proper labels
                    option.text = device.label || `Microphone ${index + 1}`;
                    audioDeviceSelect.appendChild(option);
                });
                
                // Select the current device
                if (deviceId) {
                    audioDeviceSelect.value = deviceId;
                }
                
                // Connect the microphone to the analyzer
                if (microphone) {
                    microphone.disconnect();
                }
                
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyzer);
                
                // Stop the default animation
                if (animationFrame) {
                    cancelAnimationFrame(animationFrame);
                    animationFrame = null;
                }
                
                // Start the audio visualization
                isAudioRunning = true;
                visualize();
                
                // Update UI state
                document.getElementById('start-audio').disabled = true;
                document.getElementById('stop-audio').disabled = false;
                audioDeviceSelect.disabled = true;
                refreshDevicesBtn.disabled = true;
                
                debugInfo.textContent = "Microphone connected and active";
                
            } catch (error) {
                console.error("Error accessing microphone:", error);
                debugInfo.textContent = `Error: ${error.message}`;
                
                // Show a more helpful error message
                if (error.name === 'NotAllowedError') {
                    alert("Microphone access was denied. Please allow microphone access in your browser settings and try again.");
                } else {
                    alert(`Unable to access the microphone: ${error.message}`);
                }
                
                // Reset UI state
                document.getElementById('start-audio').disabled = false;
                document.getElementById('stop-audio').disabled = true;
                audioDeviceSelect.disabled = false;
                refreshDevicesBtn.disabled = false;
                
                // Refresh the device list to ensure we're showing what's available
                loadAudioDevices();
            }
        }
        
        // Process audio data and update visualization
        function visualize() {
            if (!isAudioRunning) return;
            
            // Create array for frequency data
            const bufferLength = analyzer.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            // Get frequency data
            analyzer.getByteFrequencyData(dataArray);
            
            // Divide frequency range into 5 bands for each shape
            const bands = [];
            const totalBands = 5;
            
            // Define frequency ranges with more emphasis on lower frequencies
            const frequencyRanges = [
                { min: 20, max: 100 },     // Bass
                { min: 100, max: 250 },    // Low-mid
                { min: 250, max: 500 },    // Mid
                { min: 500, max: 2000 },   // High-mid
                { min: 2000, max: 8000 }   // High
            ];
            
            // Calculate the Nyquist frequency (half the sample rate)
            const nyquist = audioContext.sampleRate / 2;
            
            // Calculate bands with proper frequency mapping
            for (let i = 0; i < totalBands; i++) {
                const range = frequencyRanges[i];
                
                // Convert frequency to bin index
                const minBin = Math.floor(range.min / nyquist * bufferLength);
                const maxBin = Math.floor(range.max / nyquist * bufferLength);
                
                let sum = 0;
                let count = 0;
                let peak = 0;
                
                // Calculate average and peak values for this frequency band
                for (let j = minBin; j < maxBin && j < bufferLength; j++) {
                    const value = dataArray[j];
                    sum += value;
                    count++;
                    peak = Math.max(peak, value);
                }
                
                // Blend average and peak for more dynamic visualization
                const average = count > 0 ? sum / count : 0;
                const blended = (average * 0.6 + peak * 0.4) / 255;
                
                // Apply stronger nonlinear scaling for more dramatic effect
                const scaled = Math.pow(blended, 0.65); // More aggressive scaling (was 0.8)
                
                bands.push(scaled);
            }
            
            // Update debug info
            debugInfo.textContent = `Audio active | Levels: ${bands.map(b => Math.round(b * 100)).join('%, ')}%`;
            
            // Update each path based on its frequency band
            paths.forEach((path, index) => {
                const intensity = bands[index];
                
                // Emphasize intensity to make the effect more dramatic
                const enhancedIntensity = Math.pow(intensity, 0.7); // Make low-mid values stronger
                
                // Create a proper transition between default state and animation states
                let targetState;
                
                if (enhancedIntensity < 0.05) {
                    // At very low levels (near 0), use exact R.svg size (keyframe 0)
                    targetState = keyframes[0];
                } else if (enhancedIntensity < 0.2) {
                    // At low levels, transition between default and contracted
                    const normalizedIntensity = enhancedIntensity / 0.2;
                    targetState = {
                        rightX: lerp(keyframes[0].rightX, keyframes[1].rightX, normalizedIntensity),
                        leftX: lerp(keyframes[0].leftX, keyframes[1].leftX, normalizedIntensity),
                        topY: lerp(keyframes[0].topY, keyframes[1].topY, normalizedIntensity),
                        bottomY: lerp(keyframes[0].bottomY, keyframes[1].bottomY, normalizedIntensity),
                        centerY: 30,
                        centerX: 8
                    };
                } else {
                    // At higher levels, transition to expanded state
                    const normalizedIntensity = (enhancedIntensity - 0.2) / 0.8;
                    targetState = {
                        rightX: lerp(keyframes[1].rightX, keyframes[2].rightX, normalizedIntensity),
                        leftX: lerp(keyframes[1].leftX, keyframes[2].leftX, normalizedIntensity),
                        topY: lerp(keyframes[1].topY, keyframes[2].topY, normalizedIntensity),
                        bottomY: lerp(keyframes[1].bottomY, keyframes[2].bottomY, normalizedIntensity),
                        centerY: 30,
                        centerX: 8
                    };
                }
                
                updatePath(path, targetState);
            });
            
            // Continue the visualization loop
            requestAnimationFrame(visualize);
        }
        
        // Update path with the current shape state
        function updatePath(path, state) {
            // Get the current transform attribute to preserve positioning
            const transform = path.getAttribute('transform');
            
            // Create the path for the R shape with animation
            const newPath = `
                M${state.rightX} ${state.centerY}
                C${1.6278} ${35.8581} ${13.8786} ${46.6175} ${state.centerX} ${state.bottomY}
                C${2.12138} ${46.6175} ${13.3619} ${35.8581} ${state.leftX} ${state.centerY}
                C${13.3722} ${24.1419} ${2.12138} ${13.3825} ${state.centerX} ${state.topY}
                C${13.8786} ${13.3825} ${1.63809} ${24.1419} ${state.rightX} ${state.centerY}
            `.replace(/\s+/g, ' ').trim();
            
            // Apply the new path while keeping the transform
            path.setAttribute('d', newPath);
        }
        
        // Update a path's shape based on audio intensity (for visualization)
        function updatePathWithIntensity(path, intensity) {
            // Scale the intensity for better visual effect
            const scaledIntensity = Math.min(1, intensity * 1.5);
            
            // Map intensity to animation keyframes
            let targetKeyframe;
            
            if (scaledIntensity < 0.5) {
                // Interpolate between keyframes 0 and 1
                targetKeyframe = {
                    rightX: lerp(keyframes[0].rightX, keyframes[1].rightX, scaledIntensity * 2),
                    leftX: lerp(keyframes[0].leftX, keyframes[1].leftX, scaledIntensity * 2),
                    topY: lerp(keyframes[0].topY, keyframes[1].topY, scaledIntensity * 2),
                    bottomY: lerp(keyframes[0].bottomY, keyframes[1].bottomY, scaledIntensity * 2),
                    centerY: keyframes[0].centerY,
                    centerX: keyframes[0].centerX
                };
            } else {
                // Interpolate between keyframes 1 and 2
                const adjustedIntensity = (scaledIntensity - 0.5) * 2;
                targetKeyframe = {
                    rightX: lerp(keyframes[1].rightX, keyframes[2].rightX, adjustedIntensity),
                    leftX: lerp(keyframes[1].leftX, keyframes[2].leftX, adjustedIntensity),
                    topY: lerp(keyframes[1].topY, keyframes[2].topY, adjustedIntensity),
                    bottomY: lerp(keyframes[1].bottomY, keyframes[2].bottomY, adjustedIntensity),
                    centerY: keyframes[1].centerY,
                    centerX: keyframes[1].centerX
                };
            }
            
            updatePath(path, targetKeyframe);
        }
        
        // Stop the audio processing
        function stopAudio() {
            if (microphone && audioContext) {
                microphone.disconnect();
            }
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            
            isAudioRunning = false;
            
            // Update UI
            document.getElementById('start-audio').disabled = false;
            document.getElementById('stop-audio').disabled = true;
            audioDeviceSelect.disabled = false;
            refreshDevicesBtn.disabled = false;
            
            debugInfo.textContent = "Audio stopped";
            
            // Start the default animation again
            startDefaultAnimation();
        }
        
        // Event listeners
        document.getElementById('start-audio').addEventListener('click', setupAudio);
        document.getElementById('stop-audio').addEventListener('click', stopAudio);
        refreshDevicesBtn.addEventListener('click', async () => {
            // Visual feedback
            refreshDevicesBtn.textContent = "‚ü≤";
            refreshDevicesBtn.disabled = true;
            
            try {
                // Try to get microphone permission temporarily if we don't have it already
                // This will ensure we get device labels
                if (!stream) {
                    try {
                        const tempStream = await navigator.mediaDevices.getUserMedia({audio: true});
                        // Stop it right away, we just needed permissions
                        tempStream.getTracks().forEach(track => track.stop());
                    } catch (err) {
                        // If user denies permission, just continue without labels
                        console.warn("Could not get microphone permission for device refresh:", err);
                    }
                }
                
                // Force the browser to update device list
                await navigator.mediaDevices.getUserMedia({audio: true, video: false})
                    .then(tempStream => tempStream.getTracks().forEach(track => track.stop()))
                    .catch(() => {});
                
                // Now reload the devices
                await loadAudioDevices();
                
                debugInfo.textContent = "Device list refreshed";
            } catch (error) {
                console.error("Error refreshing device list:", error);
                debugInfo.textContent = `Refresh error: ${error.message}`;
            } finally {
                // Restore button state
                refreshDevicesBtn.textContent = "‚ü≥";
                refreshDevicesBtn.disabled = false;
            }
        });
        
        // Check for secure context
        if (!window.isSecureContext) {
            debugInfo.textContent = "WARNING: Audio may not work - page not in secure context";
        }
        
        // Initialize
        loadAudioDevices();
        startDefaultAnimation();
    </script>
</body>
</html> 